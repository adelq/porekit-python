{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset For Group Classification\n",
    "\n",
    "This notebook does the following:\n",
    "\n",
    "* Download three bacterial genomes:\n",
    "  * E. Coli\n",
    "  * M. Tuberculosis\n",
    "  * S. Aureus\n",
    "\n",
    "* Simulate reads of length 500 from each genome\n",
    "* Save them into a HDF5 File as Training and Validation set\n",
    "\n",
    "\n",
    "The subsequent notebook will then learn a model to classify these 500-event-fragments into their source genomes.\n",
    "\n",
    "**Warning**: This example requires a few different libraries like SciKit Bio, Keras and Theano. Your best bet is to work from an Anaconda distribution!\n",
    "\n",
    "**Warning**: This example is not yet polished to the point that it is easy to run. Patience please!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Please change E-Mail!\n",
    "from Bio import Entrez\n",
    "Entrez.email = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import porekit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import skbio\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three species where the first thing which came to my mind for the question \"What are three very different bacteria?\" I searched for genomes in the refseq database and picked these accessions, mostly because they were the first in the search results.\n",
    "\n",
    "Of course it would also be possible to use more genomes per species.\n",
    "\n",
    "And yes, I know, that instead of fancy sequencing and bioinformatics, a simple microscope and a couple of stains would suffice to distinguish these three groups ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>accession</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E_Coli_Sakai</th>\n",
       "      <td>E_Coli_Sakai</td>\n",
       "      <td>E_Coli_Sakai.fasta</td>\n",
       "      <td>NC_002695.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_Tuberculosis</th>\n",
       "      <td>M_Tuberculosis</td>\n",
       "      <td>M_Tuberculosis.fasta</td>\n",
       "      <td>NC_000962.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_Aureus</th>\n",
       "      <td>S_Aureus</td>\n",
       "      <td>S_Aureus.fasta</td>\n",
       "      <td>AP008934.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    short_name             file_name    accession\n",
       "short_name                                                       \n",
       "E_Coli_Sakai      E_Coli_Sakai    E_Coli_Sakai.fasta  NC_002695.1\n",
       "M_Tuberculosis  M_Tuberculosis  M_Tuberculosis.fasta  NC_000962.3\n",
       "S_Aureus              S_Aureus        S_Aureus.fasta   AP008934.1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources_list = [(\"E_Coli_Sakai\", \"E_Coli_Sakai.fasta\", \"NC_002695.1\"),\n",
    "                (\"M_Tuberculosis\", \"M_Tuberculosis.fasta\", \"NC_000962.3\"),\n",
    " (\"S_Aureus\", \"S_Aureus.fasta\", \"AP008934.1\"),\n",
    "]\n",
    "sources = pd.DataFrame(sources_list, columns=[\"short_name\", \"file_name\", \"accession\"])\n",
    "sources.index = sources.short_name\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download from Entrez\n",
    "for key, row in sources.iterrows():\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id=row.accession, rettype=\"fasta\", retmode=\"text\")\n",
    "    data = handle.read()\n",
    "    with open(row.file_name, \"wt\") as f:\n",
    "        f.write(data)\n",
    "sequences = dict({key:next(skbio.read(row.file_name, format=\"fasta\")) for key, row in sources.iterrows()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"model\" table inside Fast5 files references the voltages expected of all possible kmers. Both the event level and standard deviations are given with mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kmer</th>\n",
       "      <th>level_mean</th>\n",
       "      <th>level_stdv</th>\n",
       "      <th>sd_mean</th>\n",
       "      <th>sd_stdv</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b'AAAAAA'</th>\n",
       "      <td>b'AAAAAA'</td>\n",
       "      <td>62.784241</td>\n",
       "      <td>0.841324</td>\n",
       "      <td>0.664989</td>\n",
       "      <td>0.206892</td>\n",
       "      <td>1445.771698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b'AAAAAC'</th>\n",
       "      <td>b'AAAAAC'</td>\n",
       "      <td>58.017544</td>\n",
       "      <td>0.664955</td>\n",
       "      <td>0.704270</td>\n",
       "      <td>0.225492</td>\n",
       "      <td>1661.675444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b'AAAAAG'</th>\n",
       "      <td>b'AAAAAG'</td>\n",
       "      <td>62.984396</td>\n",
       "      <td>0.796764</td>\n",
       "      <td>0.689218</td>\n",
       "      <td>0.218302</td>\n",
       "      <td>1240.670417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b'AAAAAT'</th>\n",
       "      <td>b'AAAAAT'</td>\n",
       "      <td>61.414159</td>\n",
       "      <td>0.813223</td>\n",
       "      <td>0.827014</td>\n",
       "      <td>0.286941</td>\n",
       "      <td>1353.020413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b'AAAACA'</th>\n",
       "      <td>b'AAAACA'</td>\n",
       "      <td>56.506612</td>\n",
       "      <td>0.697534</td>\n",
       "      <td>0.713271</td>\n",
       "      <td>0.229829</td>\n",
       "      <td>1206.435764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                kmer  level_mean  level_stdv   sd_mean   sd_stdv       weight\n",
       "kmer                                                                         \n",
       "b'AAAAAA'  b'AAAAAA'   62.784241    0.841324  0.664989  0.206892  1445.771698\n",
       "b'AAAAAC'  b'AAAAAC'   58.017544    0.664955  0.704270  0.225492  1661.675444\n",
       "b'AAAAAG'  b'AAAAAG'   62.984396    0.796764  0.689218  0.218302  1240.670417\n",
       "b'AAAAAT'  b'AAAAAT'   61.414159    0.813223  0.827014  0.286941  1353.020413\n",
       "b'AAAACA'  b'AAAACA'   56.506612    0.697534  0.713271  0.229829  1206.435764"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru9 =  pd.read_hdf(\"../data/ru9_meta.h5\", \"meta\")\n",
    "fn = ru9[ru9.template_length > 3000].iloc()[0].absolute_filename\n",
    "fast5 = porekit.Fast5File(fn)\n",
    "model = fast5.get_model()\n",
    "model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Datasets\n",
    "\n",
    "Sample sequences from the genomes, then turn them into squiggles by sampling normally distributed events according to the model. This is done using porekit's `make_squiggle` function. `make_dataset` also partitions the genomes into pieces of 100kb, selecting odd or even numbered pieces according to the `parity` parameter. This is to make sure training and validation data is sampled from different parts of the genome. That way, the validation accuracy should not be affected by the recognition of individual genes/regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dataset(num_samples, m=500, parity=0):\n",
    "    o = len(sources)\n",
    "    k = len(model.index.values[0])\n",
    "    X = np.zeros((num_samples*3, m))\n",
    "    \n",
    "    y = np.zeros((num_samples*3))\n",
    "    i = 0\n",
    "    for key, row in sources.iterrows():\n",
    "        \n",
    "        seq = sequences[key]\n",
    "        l = len(seq)-m-k\n",
    "        y[i:i+num_samples] = i / num_samples\n",
    "        for j in range(i, i+num_samples):\n",
    "            while True:\n",
    "                a = np.random.randint(0, l)\n",
    "                \n",
    "                if (a // 1e6) % 2 != parity:\n",
    "                    continue\n",
    "                b = a+m+k\n",
    "                sub = seq[a:b]\n",
    "                if not \"N\" in sub:\n",
    "                    break\n",
    "            X[j,:] = porekit.make_squiggle(sub, model)\n",
    "            if j%100==0:\n",
    "                print(j)\n",
    "        i += num_samples    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Training Dataset of 3*10000*500 events\n",
    "\n",
    "fn = 'gclassify_11.h5'\n",
    "try:\n",
    "    os.remove(fn)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "X1,y1 = make_dataset(10000,m=500, parity=0)\n",
    "h5f = h5py.File(fn, 'w')\n",
    "h5f.create_dataset('training/X', data=X1)\n",
    "h5f.create_dataset('training/y', data=y1)\n",
    "\n",
    "# Create Validation Dataset of 3*2500*500 events\n",
    "X,y = make_dataset(2500,m=500, parity=1)\n",
    "h5f.create_dataset('validation/X', data=X)\n",
    "h5f.create_dataset('validation/y', data=y)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -ltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
