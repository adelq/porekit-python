{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Classifier\n",
    "\n",
    "\n",
    "The classification task is as follows: Given a sequence of 500 raw events, recognize the source genome.\n",
    "\n",
    "**Warning**: This example is not yet polished to the point that it is easy to run. Patience please!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import porekit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import random\n",
    "import h5py\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "def transform_y(y):\n",
    "    y = y.reshape(len(y),1)\n",
    "    return enc.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_x(x, mean, std):\n",
    "    n,m = x.shape\n",
    "    x.shape = (n, m, 1)\n",
    "    x = (x-mean) / std\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been saved to an hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5f = h5py.File('gclassify_10.h5', 'r')\n",
    "training_X = h5f['training/X'][:]\n",
    "mean, std = training_X.mean(), training_X.std()\n",
    "training_X  = transform_x(training_X, mean, std)\n",
    "\n",
    "\n",
    "training_y = transform_y(h5f['training/y'][:])\n",
    "training_yc = h5f['training/y'][:]\n",
    "validation_X = transform_x(h5f['validation/X'][:], mean, std)\n",
    "validation_y = transform_y(h5f['validation/y'][:])\n",
    "validation_yc = h5f['validation/y'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a high-level deep learning library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.core import Dense, Activation, Dropout,  Flatten\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.regularizers import l2, activity_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is relatively \"shallow\" as far as deep learning goes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(nb_filter=32,\n",
    "                        filter_length=3,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1,\n",
    "                        input_shape=(500,1),\n",
    "                        #W_regularizer= l2(0.01),\n",
    "                       ))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling1D(pool_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_dim=100, init=\"glorot_uniform\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=3, init=\"glorot_uniform\"))\n",
    "model.add(Activation(\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.05, momentum=0.05, nesterov=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 39s - loss: 0.3075    \n",
      "0.90 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 39s - loss: 0.3045    \n",
      "0.90 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 40s - loss: 0.2973    \n",
      "0.92 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 39s - loss: 0.2898    \n",
      "0.81 0.68\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 39s - loss: 0.2900    \n",
      "0.92 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 40s - loss: 0.2890    \n",
      "0.96 0.73\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 39s - loss: 0.2860    \n",
      "0.90 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 40s - loss: 0.2813    \n",
      "0.97 0.73\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 42s - loss: 0.2740    \n",
      "0.94 0.73\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 41s - loss: 0.2716    \n",
      "0.92 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 42s - loss: 0.2639    \n",
      "0.94 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 42s - loss: 0.2631    \n",
      "0.96 0.73\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 41s - loss: 0.2671    \n",
      "0.92 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 41s - loss: 0.2628    \n",
      "0.97 0.73\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 37s - loss: 0.2557    \n",
      "0.89 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 38s - loss: 0.2533    \n",
      "0.87 0.68\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 41s - loss: 0.2521    \n",
      "0.89 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 39s - loss: 0.2544    \n",
      "0.84 0.67\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 41s - loss: 0.2499    \n",
      "0.89 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 41s - loss: 0.2470    \n",
      "0.84 0.68\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 41s - loss: 0.2336    \n",
      "0.87 0.68\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 41s - loss: 0.2389    \n",
      "0.89 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 41s - loss: 0.2422    \n",
      "0.95 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 41s - loss: 0.2336    \n",
      "0.91 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 42s - loss: 0.2303    \n",
      "0.91 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 38s - loss: 0.2357    \n",
      "0.88 0.68\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 39s - loss: 0.2290    \n",
      "0.98 0.73\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 39s - loss: 0.2251    \n",
      "0.97 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 46s - loss: 0.2222    \n",
      "0.90 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 47s - loss: 0.2270    \n",
      "0.92 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 46s - loss: 0.2208    \n",
      "0.96 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 45s - loss: 0.2211    \n",
      "0.98 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 44s - loss: 0.2179    \n",
      "0.82 0.65\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 45s - loss: 0.2157    \n",
      "0.96 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 47s - loss: 0.2159    \n",
      "0.95 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 47s - loss: 0.2110    \n",
      "0.88 0.68\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 49s - loss: 0.2127    \n",
      "0.97 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 50s - loss: 0.2049    \n",
      "0.90 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.2137    \n",
      "0.91 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.2043    \n",
      "0.85 0.65\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.2006    \n",
      "0.94 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 46s - loss: 0.2041    \n",
      "0.97 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 47s - loss: 0.2019    \n",
      "0.98 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1952    \n",
      "0.96 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 51s - loss: 0.1996    \n",
      "0.80 0.63\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 47s - loss: 0.1947    \n",
      "0.85 0.66\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 47s - loss: 0.1959    \n",
      "0.97 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1912    \n",
      "0.97 0.73\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 50s - loss: 0.1972    \n",
      "0.93 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 49s - loss: 0.1917    \n",
      "0.93 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1899    \n",
      "0.95 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 47s - loss: 0.1903    \n",
      "0.94 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1894    \n",
      "0.97 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1868    \n",
      "0.97 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1887    \n",
      "0.90 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 51s - loss: 0.1834    \n",
      "0.97 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 51s - loss: 0.1840    \n",
      "0.95 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 52s - loss: 0.1871    \n",
      "0.98 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 51s - loss: 0.1846    \n",
      "0.96 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 53s - loss: 0.1780    \n",
      "0.92 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 52s - loss: 0.1834    \n",
      "0.94 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 52s - loss: 0.1818    \n",
      "0.97 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 55s - loss: 0.1746    \n",
      "0.92 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 52s - loss: 0.1788    \n",
      "0.97 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 51s - loss: 0.1768    \n",
      "0.95 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 56s - loss: 0.1683    \n",
      "0.89 0.68\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 51s - loss: 0.1805    \n",
      "0.98 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 51s - loss: 0.1729    \n",
      "0.83 0.65\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 52s - loss: 0.1777    \n",
      "0.96 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 50s - loss: 0.1710    \n",
      "0.98 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 50s - loss: 0.1732    \n",
      "0.98 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 46s - loss: 0.1678    \n",
      "0.99 0.72\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 47s - loss: 0.1709    \n",
      "0.91 0.68\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1666    \n",
      "0.95 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 49s - loss: 0.1683    \n",
      "0.98 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1648    \n",
      "0.96 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 47s - loss: 0.1659    \n",
      "0.90 0.67\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1701    \n",
      "0.97 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 49s - loss: 0.1675    \n",
      "0.96 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1642    \n",
      "0.97 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 50s - loss: 0.1590    \n",
      "0.95 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 49s - loss: 0.1660    \n",
      "0.94 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 49s - loss: 0.1579    \n",
      "0.93 0.69\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 50s - loss: 0.1652    \n",
      "0.96 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1584    \n",
      "0.98 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 47s - loss: 0.1599    \n",
      "0.97 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1660    \n",
      "0.97 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 49s - loss: 0.1565    \n",
      "0.96 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1613    \n",
      "0.98 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 49s - loss: 0.1628    \n",
      "0.95 0.70\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1586    \n",
      "0.98 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 49s - loss: 0.1608    \n",
      "0.98 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 48s - loss: 0.1561    \n",
      "0.97 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 49s - loss: 0.1576    \n",
      "0.98 0.71\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 50s - loss: 0.1538    \n",
      "0.97 0.71\n",
      "Epoch 1/1\n",
      "  576/30000 [..............................] - ETA: 49s - loss: 0.1503"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-4fd45cbd177c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0maccuracy_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_yc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/andi/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, show_accuracy, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m                          \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m                          shuffle=shuffle, metrics=metrics)\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/andi/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, metrics)\u001b[0m\n\u001b[0;32m    278\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/andi/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/andi/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(120):\n",
    "    model.fit(training_X, training_y, nb_epoch=1, batch_size=64)\n",
    "    shuffle = np.random.choice(np.arange(len(training_X)), 1000, False)\n",
    "    y = model.predict(training_X[shuffle])\n",
    "    accuracy_training = np.sum(np.isclose(y.argmax(axis=1),training_yc[shuffle])) / len(y)\n",
    "    y = model.predict(validation_X)\n",
    "    accuracy_validation = np.sum(np.isclose(y.argmax(axis=1),validation_yc)) / len(y)\n",
    "    print(\"%.2f %.2f\" % (accuracy_training, accuracy_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The model doesn't seem to overfit very much. Yes, the accuracy on the training data is higher than on the validation data, but the validation error doesn't increase either.\n",
    "\n",
    "My most recent run achieved 97% training and 71% validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
