{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Classifier\n",
    "\n",
    "\n",
    "The classification task is as follows: Given a sequence of 500 raw events, recognize the source genome.\n",
    "\n",
    "**Warning**: This example is not yet polished to the point that it is easy to run. Patience please!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import porekit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import random\n",
    "import h5py\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "def transform_y(y):\n",
    "    y = y.reshape(len(y),1)\n",
    "    return enc.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_x(x, mean, std):\n",
    "    n,m = x.shape\n",
    "    x.shape = (n, m, 1)\n",
    "    x = (x-mean) / std\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been saved to an hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5f = h5py.File('gclassify_11.h5', 'r')\n",
    "training_X = h5f['training/X'][:]\n",
    "mean, std = training_X.mean(), training_X.std()\n",
    "training_X  = transform_x(training_X, mean, std)\n",
    "\n",
    "training_y = transform_y(h5f['training/y'][:])\n",
    "training_yc = h5f['training/y'][:]\n",
    "validation_X = transform_x(h5f['validation/X'][:], mean, std)\n",
    "validation_y = transform_y(h5f['validation/y'][:])\n",
    "validation_yc = h5f['validation/y'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a high-level deep learning library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/andi/anaconda3/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.core import Dense, Activation, Dropout,  Flatten\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.regularizers import l2, activity_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is relatively \"shallow\" as far as deep learning goes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(nb_filter=32,\n",
    "                        filter_length=3,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1,\n",
    "                        input_shape=(500,1),\n",
    "                        #W_regularizer= l2(0.01),\n",
    "                       ))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling1D(pool_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_dim=100, init=\"glorot_uniform\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=3, init=\"glorot_uniform\"))\n",
    "model.add(Activation(\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.001, nesterov=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "65280/90000 [====================>.........] - ETA: 30s - loss: 0.3974"
     ]
    }
   ],
   "source": [
    "for i in range(120):\n",
    "    model.fit(training_X, training_y, nb_epoch=1, batch_size=64)\n",
    "    shuffle = np.random.choice(np.arange(len(training_X)), 1000, False)\n",
    "    y = model.predict(training_X[shuffle])\n",
    "    accuracy_training = np.sum(np.isclose(y.argmax(axis=1),training_yc[shuffle])) / len(y)\n",
    "    y = model.predict(validation_X)\n",
    "    accuracy_validation = np.sum(np.isclose(y.argmax(axis=1),validation_yc)) / len(y)\n",
    "    print(\"%.2f %.2f\" % (accuracy_training, accuracy_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The model doesn't seem to overfit very much. Yes, the accuracy on the training data is higher than on the validation data, but the validation error doesn't increase either.\n",
    "\n",
    "My most recent run achieved 97% training and 71% validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
